# mini-transformer-lab

A compact transformer-based language model built from scratch in pure PyTorch — designed for learning, tinkering, and really understanding how LLMs work under the hood.

> 🔬 **Built with curiosity, debugged with persistence**
> 
> Almost every error and bug in this project was debugged (sometimes painfully) with a bit of help from AI tools — and yeah, my brain had its fair share of contributions too in debugging, coding, and the whole idea. Because honestly, what else would you expect from a self-taught Python programmer building their own LLM?

## 🎯 What's Inside
mini-transformer-lab/
├── 🧠 mini_llm.py # Main model & training script
├── 📚 example_data/ # Sample texts to train on
├── 🎛️ checkpoints/ # Saved model weights
└── 🔬 experiments/ # Training logs & results

## 🚀 Quick Start

### Installation

```bash
# Clone this repository
git clone https://github.com/Aranya-Marjara/mini-transformer-lab.git
cd mini-transformer-lab

# Install dependencies (just PyTorch!)
pip install torch
